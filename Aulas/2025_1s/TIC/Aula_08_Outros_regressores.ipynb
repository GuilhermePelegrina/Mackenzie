{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuilhermePelegrina/Mackenzie/blob/main/Aulas/2025_1s/TIC/Aula_08_Outros_regressores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyXCpdAl9Y9o"
      },
      "source": [
        "<img src='https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/logo_mackenzie.png'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9tDgZeaQxjW"
      },
      "source": [
        "# **Outros modelos (não lineares) de regressão**\n",
        "\n",
        "Nas aulas passadas vimos o uso das Árvores de Decisão, Florestas Aleatórias e Redes neurais para problemas de classificação. No entanto, todos esses modelos também podem ser usados para problemas de regressão.\n",
        "\n",
        "Nesta aula, veremos como implementar tais modelos no Python. A teoria é praticamente a mesma. O que altera é que, ao invés de prever as classes (exemplo, 0 e 1), os modelos vão indicar valores contínuos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWX8IHKyk_At"
      },
      "source": [
        "## Exemplo - Auto MPG\n",
        "\n",
        "Para aplicar os métodos que serão vistos nesta aula, vamos usar o conjunto de dados chamado Auto MPG. Esse conjunto de dados pode ser extraído diretamente da biblioteca *seaborn*.\n",
        "\n",
        "Este conjunto de dados descreve o consumo de diferentes carros (medido pelo número de milhas percorridas com o uso de um galão de gasolina) com base no seguinte conjunto de características de tais carros:\n",
        "\n",
        "- cylinders -> Número de cilíndros.\n",
        "\n",
        "- displacement -> Capacidade do motor.\n",
        "\n",
        "- horsepower -> Potência (cavalo-vapor).\n",
        "\n",
        "- weight -> Peso.\n",
        "\n",
        "- acceleration -> Tempo, em segundos, até atingir a velocidade de 100 km/h (partindo do carro em repouso).\n",
        "\n",
        "- model_year -> Ano do modelo do carro\n",
        "\n",
        "- origin -> Local de produção do carro.\n",
        "\n",
        "- name -> Nome do modelo do carro.\n",
        "\n",
        "Uma característica interessante nesse dado é que ele possui variáveis categóricas, o que traz uma interpretação diferente para o coeficiente associado a elas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2qGAsSjla1S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "df = sns.load_dataset('mpg')\n",
        "df = df.dropna()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para os modelos que veremos na aula, vamos considerar os atributos *cylinders*, *displacement*, *horsepower*, *weight*, *acceleration*, *model_year* e *origin* para prever o *mpg*."
      ],
      "metadata": {
        "id": "QWgv4ET4AiMq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VUv4ygNu1bL"
      },
      "source": [
        "### Árvore de Decisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf9g0qSLu1bL"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor # Veja aqui a alteração\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Preparando os dados\n",
        "X = df.drop(columns=['mpg','name'])\n",
        "X = pd.get_dummies(X) # Dessa forma, já transformamos as dummies em categóricas no próprio DataFrame\n",
        "y = df['mpg']\n",
        "\n",
        "# Separando os dados de Treinamento e Teste\n",
        "seed = 1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
        "\n",
        "# Declarando o Modelo\n",
        "#clf = DecisionTreeRegressor(criterion='squared_error',random_state=seed)\n",
        "clf = DecisionTreeRegressor(criterion='squared_error',min_samples_leaf=5,min_samples_split=5,max_depth=None,random_state=seed)\n",
        "\n",
        "# Aprendizado\n",
        "clf.fit(X_train, y_train)                  # Emprega o conjunto de treinamento\n",
        "y_pred = clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUnbv-H1u1bL"
      },
      "source": [
        "### Avaliando o ajuste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x7c8pSMu1bM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Comparando os valores reais e os preditos\n",
        "plt.figure()\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Valores reais')\n",
        "plt.ylabel('Valores preditos')\n",
        "plt.title('Valores reais x Valores preditos')\n",
        "plt.show()\n",
        "\n",
        "print(\"Erro quadrático médio:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R^2:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reparem, agora, no resultado do modelo seguinte. Nele, colocamos como condição `max_depth=2`."
      ],
      "metadata": {
        "id": "5EwVONudE_2D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltxHdSazFFaZ"
      },
      "outputs": [],
      "source": [
        "# Declarando o Modelo\n",
        "clf = DecisionTreeRegressor(criterion='squared_error',min_samples_leaf=5,min_samples_split=5,max_depth=2,random_state=seed)\n",
        "\n",
        "# Aprendizado\n",
        "clf.fit(X_train, y_train)                  # Emprega o conjunto de treinamento\n",
        "y_pred = clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYfZJQ6lFFaZ"
      },
      "source": [
        "### Avaliando o ajuste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZflzPQ0WFFaZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Comparando os valores reais e os preditos\n",
        "plt.figure()\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Valores reais')\n",
        "plt.ylabel('Valores preditos')\n",
        "plt.title('Valores reais x Valores preditos')\n",
        "plt.show()\n",
        "\n",
        "print(\"Erro quadrático médio:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R^2:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isso acontece porque o modelo considerou apenas duas ramificações e, portanto, 4 resutlados possíveis. Veja na figura abaixo como fica a árvore neste caso. Então, no caso da regressão, o número de ramificações determina o quanto o modelo vai percorrer os possíveis valores a serem previstos. Esse valor precisa ser grande (ou deixar sem restrição)."
      ],
      "metadata": {
        "id": "b_gH387nFNWW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymCrZGYNu1bN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "\n",
        "tree.plot_tree(clf, fontsize=9)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FBS7DNOu1bN"
      },
      "source": [
        "Opções código:\n",
        "\n",
        "- **min_samples_leaf** (Número Mínimo de Amostras em uma Folha):\n",
        "Se o número de amostras em uma folha for menor do que o valor definido em **min_samples_leaf**, então a divisão (split) não será realizada e a folha será considerada pura.\n",
        "\n",
        "- **min_samples_split** (Número Mínimo de Amostras para Divisão):\n",
        "número mínimo de amostras necessárias para realizar uma divisão em um nó (um ponto onde a árvore se ramifica).\n",
        "Se o número de amostras em um nó for menor do que o valor definido em min_samples_split, então a divisão não será realizada, e esse nó se tornará uma folha (caso contrário, a árvore continuará dividindo).\n",
        "\n",
        "- **max_depth** (Profundidade Máxima da Árvore):\n",
        "Define o número máximo de níveis ou camadas que a árvore de decisão pode ter a partir do nó raiz (o topo da árvore).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63WKKM_hLBDh"
      },
      "source": [
        "### Floresta aleatória"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obMALS43LIoO"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Declarando o Modelo\n",
        "clf = RandomForestRegressor(random_state=seed)\n",
        "\n",
        "# Aprendizado\n",
        "clf.fit(X_train, y_train)                  # Emprega o conjunto de treinamento\n",
        "y_pred = clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld_WA1RFLk1X"
      },
      "source": [
        "### Avaliando o ajuste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JcmRlEqLk1Y"
      },
      "outputs": [],
      "source": [
        "# Comparando os valores reais e os preditos\n",
        "plt.figure()\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Valores reais')\n",
        "plt.ylabel('Valores preditos')\n",
        "plt.title('Valores reais x Valores preditos')\n",
        "plt.show()\n",
        "\n",
        "print(\"Erro quadrático médio:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R^2:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reparem, agora, no resultado do modelo seguinte. Nele, colocamos como condição `max_depth=2`."
      ],
      "metadata": {
        "id": "13vLBnAoL-zi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuO2gNbwL-zj"
      },
      "outputs": [],
      "source": [
        "# Declarando o Modelo\n",
        "clf = RandomForestRegressor(random_state=seed,max_depth=2)\n",
        "\n",
        "# Aprendizado\n",
        "clf.fit(X_train, y_train)                  # Emprega o conjunto de treinamento\n",
        "y_pred = clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4BR2p3RL-zk"
      },
      "source": [
        "### Avaliando o ajuste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFFTHaaLL-zk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Comparando os valores reais e os preditos\n",
        "plt.figure()\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Valores reais')\n",
        "plt.ylabel('Valores preditos')\n",
        "plt.title('Valores reais x Valores preditos')\n",
        "plt.show()\n",
        "\n",
        "print(\"Erro quadrático médio:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R^2:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reparem na diferença em relação à árvore de decisão. Neste cenário, também consideramos apenas duas ramificações e, portanto, 4 resutlados possíveis para cada árvore. Mas como temos várias árvores na floresta aleatória, mais valores são possíveis de serem alcançados no modelo de regressão."
      ],
      "metadata": {
        "id": "ckRkupXKL-zl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDuKzDRPu1bN"
      },
      "source": [
        "### Interpretando o modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um vetor contendo as importâncias atribuídas a cada atributo na base de dados usada no treinamento\n",
        "feature_importances = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "\n",
        "# Plot\n",
        "feature_importances.plot.bar();"
      ],
      "metadata": {
        "id": "dVqmmjaQgDBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse resulado indica que *displacement* é o atributo que mais contribui para prever o valor do *mpg*. Por outro lado, a indicação do país de origem dos veículos assim como a aceleração não possuem grande impacto no modelo. Esses atributos poderiam ser retirados sem prejudicar a qualidade do modelo. Veja nos códigos seguintes."
      ],
      "metadata": {
        "id": "lFzOorrMhsHm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2odW0VWNQfz"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Preparando os dados\n",
        "X2 = df.drop(columns=['mpg','name','origin','acceleration'])\n",
        "X2 = pd.get_dummies(X2) # Dessa forma, já transformamos as dummies em categóricas no próprio DataFrame\n",
        "\n",
        "# Separando os dados de Treinamento e Teste\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y, test_size=0.2, random_state=seed)\n",
        "\n",
        "# Declarando o Modelo\n",
        "clf = RandomForestRegressor(random_state=seed)\n",
        "\n",
        "# Aprendizado\n",
        "clf.fit(X_train2, y_train2)                  # Emprega o conjunto de treinamento\n",
        "y_pred = clf.predict(X_test2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP74T_sgNQf0"
      },
      "source": [
        "### Avaliando o ajuste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQGP3fEONQf0"
      },
      "outputs": [],
      "source": [
        "# Comparando os valores reais e os preditos\n",
        "plt.figure()\n",
        "plt.scatter(y_test2, y_pred)\n",
        "plt.xlabel('Valores reais')\n",
        "plt.ylabel('Valores preditos')\n",
        "plt.title('Valores reais x Valores preditos')\n",
        "plt.show()\n",
        "\n",
        "print(\"Erro quadrático médio:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R^2:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfqysWIKMjwu"
      },
      "source": [
        "### Opções código\n",
        "\n",
        "- **n_estimators**: Número de árvores de decisão que serão consideradas no *ensemble*. Lembre-se que quanto maior esse número, maior (geralmente) o desempenho do modelo e maior é tempo computacional.\n",
        "\n",
        "- **max_features** {“sqrt”, “log2”, None}: Número de atributos considerados na seleção do subconjunto para particionar cada nó das árvores. Por padrão, considera-se `sqrt`, ou seja, esse número como a raiz quadrada do número total de atributos.\n",
        "\n",
        "- **min_samples_leaf** (Número Mínimo de Amostras em uma Folha): Se o número de amostras em uma folha para cada árvore de decisão for menor do que o valor definido em **min_samples_leaf**, então a divisão (split) não será realizada e a folha será considerada pura.\n",
        "\n",
        "- **min_samples_split** (Número Mínimo de Amostras para Divisão):\n",
        "número mínimo de amostras necessárias para realizar uma divisão em um nó (um ponto onde a árvore se ramifica) em cada árvore de decisão. Se o número de amostras em um nó for menor do que o valor definido em min_samples_split, então a divisão não será realizada, e esse nó se tornará uma folha (caso contrário, a árvore continuará dividindo).\n",
        "\n",
        "- **max_depth** (Profundidade Máxima da Árvore):\n",
        "Define o número máximo de níveis ou camadas que cada árvore de decisão pode ter a partir do nó raiz (o topo da árvore).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5QqcCSEOnJS"
      },
      "source": [
        "### Redes neurais artificiais"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizando os dados\n",
        "\n",
        "X_train = (X_train - X_train.mean()) / X_train.std()\n",
        "X_test = (X_test - X_test.mean()) / X_test.std()"
      ],
      "metadata": {
        "id": "i1ZbR6lt8W4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoKFbY_gyf2Z"
      },
      "source": [
        "### Configuração e Treinamento da Rede DeepLearning\n",
        "\n",
        "Nossa rede terá:\n",
        "\n",
        "\n",
        "*   9 neurônios de entrada, correspondendo a cada atributo de entrada\n",
        "*   3 camadas ocultas de 10 neurônios cada\n",
        "*   1 camada de saída com 1 neurônio correspondendo à previsão do modelo\n",
        "\n",
        "Usaremos a função de ativação: relu.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVUC8oWhylEQ"
      },
      "source": [
        "# Treinamento ()\n",
        "\n",
        "import numpy as np\n",
        "from keras import Sequential, layers\n",
        "\n",
        "# Definição\n",
        "\n",
        "model = Sequential([layers.Dense(9, activation='relu', input_shape=[len(X_train.keys())])])\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='relu'))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "# Treinamento\n",
        "history = model.fit(np.matrix(X_train), np.transpose(np.matrix(y_train)), validation_split=0.2, epochs=400)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP1Ifdg5aDnx"
      },
      "source": [
        "### Avaliando o ajuste"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown executar!\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error')\n",
        "  plt.plot(hist['epoch'], hist['mse'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mse'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "print('completed!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zgQMWnmqSYhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrkQMDRzzmJq"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIUsGG-CaDny"
      },
      "outputs": [],
      "source": [
        "# Comparando os valores reais e os preditos\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Valores reais')\n",
        "plt.ylabel('Valores preditos')\n",
        "plt.title('Valores reais x Valores preditos')\n",
        "plt.show()\n",
        "\n",
        "print(\"Erro quadrático médio:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R^2:\", r2_score(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi31V+UeU9unrN8JKUlQhu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}