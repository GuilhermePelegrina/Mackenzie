{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs5R846VO6gSGuvWOgrytn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuilhermePelegrina/Mackenzie/blob/main/Aulas/TIC/Aula_09_Kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/logo_mackenzie.png'>\n"
      ],
      "metadata": {
        "id": "FyXCpdAl9Y9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estudo de caso: Políticas e Campanhas de não Violência\n",
        "\n",
        "É comum em políticas públicas agrupar regiões (estados, cidades ou bairros) para estabelecer diretrizes a fim de atuar em um determinado problema da sociedade. Nesta aula, vamos lidar com um caso real acerca da adoção de políticas e campanhas de não violância dos Estados Unidos.\n",
        "\n",
        "O conjunto de dados [US Arrests](https://www.kaggle.com/code/aishu2218/us-arrests-using-hierarchical-clustering-analysis) contém estatísticas de prisões por 100.000 residentes, sendo assassinato, assalto e estupro. Essas estatísticas foram extraídas dos 50 estados dos EUA. Além dessas estatísticas, também é fornecida a porcentagem da população que vive em áreas urbanas.\n",
        "\n",
        "O intuito ao usar esse conjunto de dados é de agrupar estados que possuem uma certa similaridade para, então, estabelecer políticas específicas para cada grupo obtido. Notem que, aqui, não há um valor ou uma classe a ser prevista. Ou seja, estamos em um contexto de **aprendizado não-supervisionado**.\n",
        "\n",
        "Para ler o conjunto de dados, use o link abaixo:\n",
        "\n",
        "https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/Datasets/data_banknotes.csv\n",
        "\n",
        "Nesta aula, vamos abordar esse problemas a partir do método chamado *k-means*.\n"
      ],
      "metadata": {
        "id": "I610w4UjnFmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo os dados - Note que definimos a coluna 0 como índice das linhas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dados = pd.read_csv(\"https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/Datasets/data_usarrests.csv\",index_col=0)\n",
        "dados.head()\n"
      ],
      "metadata": {
        "id": "RuJh3C8msYtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-means (ou K-médias)**"
      ],
      "metadata": {
        "id": "T9tDgZeaQxjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O método k-means é um algoritmo de aprendizado não supervisionado de agrupamento (clustering) de dados. O objetivo do algoritmo é dividir um conjunto de dados em k grupos, em que cada grupo (ou cluster) é representativo de um conjunto de dados que compartilham características similares.\n",
        "\n",
        "No **Aprendizado Não Supervisionado** o algoritmo é treinado para encontrar padrões em um conjunto de dados **sem a necessidade de uma categoria (ou variável resposta)**\n",
        "\n",
        "Diferentemente do Aprendizado Supervisionado, no Aprendizado não Supervisionado **não há um Conjunto de Treinamento**, e portanto não haverá também um Conjunto de Testes. O aprendizado é feito sobre os dados, capturando algum padrão dos dados, mas sem uma `resposta`, como um valor ou classe, como você encontrou no Aprendizado Supervisionado. Neste sentido dizemos que o **Aprendizado não Supervisionado é mais Analítico que Preditivo**."
      ],
      "metadata": {
        "id": "RwQgorNWgvmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplos de uso de k-means:\n",
        "\n",
        "- **Grupo de clientes**: uma loja de *e-commerce* pode usar o método K-means para agrupar seus clientes em diferentes com base em seus históricos de compras e comportamentos de navegação no site. Isso pode ajudar o e-commerce a personalizar suas campanhas de *marketing* para cada grupo.\n",
        "\n",
        "- **Análise de imagens:** Uma imagem pode ser segmentada em diferentes grupos usando o método k-means com base em suas características, como cor e textura. Isso pode ser útil em aplicações de reconhecimento de imagem.\n",
        "\n",
        "- **Detecção de padrões de consumo em diferentes bairros:** Uma rede de supermercado pode, por exemplo, agrupar suas lojas localizadas em diferentes bairros para entender o padrão de consumo de cada população de tais bairros. E, assim, estabelecer estratégias de estoque e vendas mais apropriadas para cada loja."
      ],
      "metadata": {
        "id": "3EyHVjAyheaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Como funciona o método de k-means?"
      ],
      "metadata": {
        "id": "TpNFwPReiWA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/Aulas/Figuras/fig_kmeans_method.png'>\n",
        "\n",
        "O método consite em construir k *clusters* a partir de um conjunto de dados, em que o número de *clusters* a serem formados é escolhido pelo usuário. A escolha do número de clusters no algoritmo K-means é um desafio importante na análise de dados.\n",
        "\n",
        "*   Se o valor de **k for muito pequeno** (poucos grupos), cada cluster pode conter muitos pontos de dados, resultando em uma segmentação grosseira dos dados e perda de informações importantes.\n",
        "*   Se o valor de **k for muito grande** em relação ao tamanho do conjunto de dados, cada cluster pode conter muito poucos pontos de dados, tornando a segmentação inadequada e difícil de interpretar."
      ],
      "metadata": {
        "id": "e9EHpUohivsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Passos para usar o método k-means:**\n",
        "\n",
        "1.   Definir um k (um número de clusters ou agrupamentos).\n",
        "2.   Escolher, aleatoriamente, o centro para cada cluster (centroide).\n",
        "3.   Calcular a distância de cada ponto (dado) aos centroides. Cada ponto pertencerá ao centroide mais próximo\n",
        "4.   Reposicionar o centróide, a nova posição do centroide deve ser a média da posição de todos os pontos do cluster.\n",
        "\n",
        "Os dois ultimos passos são repetidos, iterativamente, até obtermos os clusters finais. A ideia é minimizar as distâncias intragrupos e maximizar as distâncias entre grupos.\n",
        "\n",
        "Minimizar as distâncias intragrupos:\n",
        "$$ min_{c} J_{in} = \\sum_{i,k} || x_i - c_k ||^2 $$\n",
        "\n",
        "Maximizar as distâncias entre grupos.\n",
        "\n",
        "$$ max_{c} J_{out} = \\sum_{i,k} || c_i - c_k ||^2 $$\n",
        "\n",
        "Aqui empregaremos unicamente a **distância Euclidiana** embora outras funções distância possam ser empregadas.\n",
        "\n",
        "**Observação:** O método k-means é sensível às unidades e escalas dos dados. Isso significa que se os dados não estiverem normalizados ou padronizados, os resultados da clusterização podem ser distorcidos ou menos confiáveis.\n"
      ],
      "metadata": {
        "id": "fr5CaLhPjzIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo unidimensional"
      ],
      "metadata": {
        "id": "89PBydQg-lid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suponha que temos os seguintes valores:\n",
        "\n",
        "$$[1; 1,5; 2; 4; 5; 6; 7; 8; 9; 10]$$\n"
      ],
      "metadata": {
        "id": "ZKywGdHc-nWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Digamos que desejamos dividir esses valores em **3 clusters**.\n",
        "\n",
        "Vamos selecionar, aleatoriamente, os 3 centroides (centro para cada cluster)\n",
        "\n",
        "*   **Centroide 1:** 3\n",
        "*   **Centroide 2:** 5\n",
        "*   **Centroide 3:** 8"
      ],
      "metadata": {
        "id": "AD-v6OZk-4_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos calcular a **distância ecludiana** entre cada valor e cada centroide, e atribuímos o valor ao cluster cujo centroide é o mais próximo. (Verifiquem as contas)\n",
        "\n"
      ],
      "metadata": {
        "id": "cyrkUgLJ-7kL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Centroide 1:** [1, 1.5, 2, 4] →  Cluster 1\n",
        "*   **Centroide 2:** [5, 6, 7] →  Cluster 2\n",
        "*   **Centroide 3:** [8, 9, 10] →  Cluster 3"
      ],
      "metadata": {
        "id": "v5GitgSi_bTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, recalculamos os centroides de cada cluster, que serão a média dos valores que estão em cada cluster."
      ],
      "metadata": {
        "id": "ZHdeAVUN_pYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Centroide 1:** (1+1.5+2+4)/4 = 2.125\n",
        "*   **Centroide 2:** (5+6+7)/3 = 6\n",
        "*   **Centroide 3:** (8+9+10)/3 = 9"
      ],
      "metadata": {
        "id": "kd8JnqjF_toL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse procedimento deve-se repetir até que não não haja mais mudanças nas atribuições dos valores aos clusters. **Após algumas iterações**, podemos obter os seguintes clusters:"
      ],
      "metadata": {
        "id": "u6GbAd1v_xRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Cluster 1:** [1, 1.5, 2]\n",
        "*   **Cluster 2:** [4, 5, 6, 7]\n",
        "*   **Cluster 3:** [8, 9, 10]"
      ],
      "metadata": {
        "id": "s--m9Ekc_2if"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observação: O resultado do k-means pode depender dos valores iniciais escolhidos para os centroides"
      ],
      "metadata": {
        "id": "27TVtPrDCZM5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Uh588DVABb"
      },
      "source": [
        "### Exemplo bidimensional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Execute este código para realizar as análises que se seguem.\n",
        "\n",
        "# set up environment T11\n",
        "#\n",
        "\n",
        "#\n",
        "# import basics\n",
        "#\n",
        "\n",
        "import pandas                  as pd\n",
        "import numpy                   as np\n",
        "import matplotlib.pyplot       as plt\n",
        "import warnings\n",
        "import os\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set()\n",
        "\n",
        "# import plotly as py\n",
        "# import plotly.graph_objs as go\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Linear\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "# a little bit dirty here... just for this case...\n",
        "from scipy.spatial import distance\n",
        "def kmeansL(X,k=2,max_iterations=100,pos=[2,8]):\n",
        "    f = plt.figure(figsize=(10, 3))\n",
        "    # plt.axis('off')\n",
        "    plt.yticks([])\n",
        "    plt.ylim([-2.5,0.5])\n",
        "    # plt.xlim([0,70])\n",
        "    if isinstance(X, pd.DataFrame):X = X.values\n",
        "    idx = np.array(pos) # np.random.choice(len(X), k, replace=False)\n",
        "    centroids = X[idx, :]\n",
        "    print(list(X.T))\n",
        "    print(centroids)\n",
        "    P = np.argmin(distance.cdist(X, centroids, 'euclidean'),axis=1)\n",
        "    print(P)\n",
        "    zeros = np.full((len(X)), 0, dtype=int)\n",
        "    sns.scatterplot(X[:,0],zeros, hue=P,legend=None,marker='o',s=50)\n",
        "    sns.scatterplot(centroids[:,0],zeros[0:2], legend=None,color='black',s=100)\n",
        "    plt.text(centroids[0,0],zeros[0:1]-0.2,'C1 =' + str(np.round(centroids[0,0],1)))\n",
        "    plt.text(centroids[1,0],zeros[0:1]-0.2,'C2 =' + str(np.round(centroids[1,0],1)))\n",
        "    plt.text(15,zeros[0:1]+0.2,'i = ' + str(0))\n",
        "    for j in range(max_iterations):\n",
        "        centroids = np.vstack([X[P==i,:].mean(axis=0) for i in range(k)])\n",
        "        print(centroids)\n",
        "        tmp = np.argmin(distance.cdist(X, centroids, 'euclidean'),axis=1)\n",
        "        if np.array_equal(P,tmp):break\n",
        "        P = tmp\n",
        "        print(X.T)\n",
        "        print(P)\n",
        "        zeros = np.full((len(X)), -(j+1) , dtype=int)\n",
        "        sns.scatterplot(X[:,0],zeros, hue=P,legend=None,marker='o',s=50)\n",
        "        sns.scatterplot(centroids[:,0],zeros[0:2], legend=None,color='black',s=100)\n",
        "        plt.text(centroids[0,0],zeros[0:1]-0.2,'C1 =' + str(np.round(centroids[0,0],1)))\n",
        "        plt.text(centroids[1,0],zeros[0:1]-0.2,'C2 =' + str(np.round(centroids[1,0],1)))\n",
        "        plt.text(15,zeros[0:1]+0.2,'i = ' + str(j+1))\n",
        "\n",
        "    return P # , X, centroids\n",
        "\n",
        "'''\n",
        "P, PP, centroids = kmeansL(X,k=2,pos=[2,8])\n",
        "P, PP, centroids = kmeansL(X,k=2,pos=[2,18])\n",
        "P, PP, centroids = kmeansL(X,k=2,pos=[5,18])\n",
        "P, PP, centroids = kmeansL(X,k=2,pos=[12,15])\n",
        "'''\n",
        "\n",
        "# Spacial\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "\n",
        "def find_clusters(X, n_clusters, rseed=2):\n",
        "    # 1. Randomly choose clusters\n",
        "    rng = np.random.RandomState(rseed)\n",
        "    i = rng.permutation(X.shape[0])[:n_clusters]\n",
        "    centers = X[i]\n",
        "\n",
        "    j=0\n",
        "\n",
        "    while True:\n",
        "        # 2a. Assign labels based on closest center\n",
        "        labels = pairwise_distances_argmin(X, centers)\n",
        "\n",
        "        # 2b. Find new centers from means of points\n",
        "        new_centers = np.array([X[labels == i].mean(0)\n",
        "                                for i in range(n_clusters)])\n",
        "\n",
        "        # 2c. Check for convergence\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "\n",
        "        f = plt.figure(figsize=(5, 5))\n",
        "        plt.scatter(X[:, 0], X[:, 1], c=labels,\n",
        "            s=50, cmap='viridis');\n",
        "        plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.85);\n",
        "\n",
        "        plt.text(centers[0, 0]-0.3, centers[0, 1]+0.3, 'C1', fontsize=16, fontweight='bold')\n",
        "        plt.text(centers[1, 0]-0.3, centers[1, 1]+0.3, 'C2', fontsize=16, fontweight='bold')\n",
        "        plt.text(centers[2, 0]-0.3, centers[2, 1]+0.3, 'C3', fontsize=16, fontweight='bold')\n",
        "        plt.text(centers[3, 0]-0.3, centers[3, 1]+0.3, 'C4', fontsize=16, fontweight='bold')\n",
        "\n",
        "        plt.title('Kmeans, Iteração i= ' + str(j))\n",
        "        j=j + 1\n",
        "\n",
        "        plt.show()\n",
        "    return centers, labels\n",
        "\n",
        "# centers, labels = find_clusters(X, 4)\n",
        "\n",
        "print('Set Up completed!')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eN7wH30xKsaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos usar a função `make_blobs` do módulo para gerar um conjunto de dados sintético com blobs (\"manchas\") de pontos de dados para visualizar como funciona o algoritmo de *k-means*.\n",
        "\n",
        "A função `make_blobs` retorna uma tupla contendo:\n",
        "\n",
        "*   Uma **matriz X** com os pontos de dados gerados\n",
        "*   Um **vetor y** com as etiquetas de classe correspondentes a cada ponto de dados gerado"
      ],
      "metadata": {
        "id": "0Kb1YDyN1w1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X, y_true = make_blobs(n_samples=300, n_features=2, centers=4, cluster_std=0.60, random_state=0)\n",
        "\n",
        "X"
      ],
      "metadata": {
        "id": "BThGXeD_5ofx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `find_clusters` foi desenvolvida e está no final do notebook para visualizar o processo iterativo do método *k-means*. Não é necessário entender o código desta função apenas seu resultado."
      ],
      "metadata": {
        "id": "iNPbUzqx7UBQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXWQNdM3Bevi"
      },
      "source": [
        "centers, labels = find_clusters(X, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Cuidado:**  **Clusterização** $\\not=$ **Classificação**\n",
        "\n",
        "\n",
        "*   A clusterização é um método não supervisionado, ou seja, não é\n",
        "necessário ter categorias prévias para os dados. A ideia é agrupar os dados em clusters que sejam homogêneos internamente e heterogêneos entre si.\n",
        "*   A classificação é um tipo de aprendizado supervisionado que tem como objetivo treinar um modelo para classificar novos dados em uma ou mais categorias pré-definidas (método supervisionado)\n",
        "\n",
        "Suponha por exemplo um conjunto de dados de Empréstimos onde eles são classificados entre *Tx Padrão* e *Tx Especial* (juros mais baixos). Essa é a classificação dos dados. Mas, se você buscar com alguma técnica \"grupos de Empréstimos\" que guardem semelhanças entre si, talvez você encontre grupos  que exibem um outra relação dos dados completamente diferente de *Tx Padrão* e *Tx Especial*. Por exemplo, grupos de Empréstimos para Bens de Consumo para Jovens, Empréstimos para Capital de Giro e Outros, em todos eles havendo seus percentuais de *Tx Padrão* e *Tx Especial*.\n",
        "\n",
        "Você ainda não vai empregar essa informação para *predizer* novos casos, mas talvez tomar decisões sobre esses grupos, como fazer uma campanha para educação de Jovens sobre o Empréstimo Consciente ou uma redução das Taxas para atrair mais Empréstimos de Capital de Giro."
      ],
      "metadata": {
        "id": "bUTPrAMsC7Ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retomando: Políticas e Campanhas de não Violência\n",
        "\n",
        "Relembtando, no conjunto de dados [US Arrests](https://www.kaggle.com/code/aishu2218/us-arrests-using-hierarchical-clustering-analysis), há estatísticas de prisões por 100.000 residentes, sendo assassinato, assalto e estupro. Essas estatísticas foram extraídas dos 50 estados dos EUA. Além dessas estatísticas, também é fornecida a porcentagem da população que vive em áreas urbanas.\n"
      ],
      "metadata": {
        "id": "KhVqiNgE3_X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura dos dados - Note que definimos a coluna 0 como índice das linhas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dados = pd.read_csv(\"https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/Datasets/data_usarrests.csv\",index_col=0)\n",
        "dados.head()\n",
        "\n",
        "dados = pd.read_csv(\"https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/Datasets/data_usarrests.csv\",index_col=0)\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "Z-GC0VXTDnhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando células vazias\n",
        "\n",
        "dados.isnull().sum()"
      ],
      "metadata": {
        "id": "CYg1tZc9Gq7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que os dados encontram-se em **escalas diferentes e o método k- means é sensível a distância**, vamos reescalar os dados empregando a função `StandardScaler`.\n",
        "\n",
        "**Cuidado!** Para usar k-means precisamos que os dados estejam em um *DataFrame*"
      ],
      "metadata": {
        "id": "iEhPkAH6AVV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_matrix = StandardScaler().fit(dados).transform(dados)\n",
        "\n",
        "dados = pd.DataFrame(X_matrix,columns=dados.columns, index=dados.index)\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "ZMqj2hrcG7Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definindo o número ideal de Clusters\n",
        "\n",
        "Não há uma regra para escolher o número ideal de clusters, mas existem algumas técnicas que podem ajudar na escolha. Destacam-se os métodos: cotovelo, silhueta e da curvatura. Aqui vamos empregar apenas o método do cotovelo.\n",
        "\n",
        "O **método do cotovelo** envolve plotar a **inércia** em relação ao número de clusters. O número ideal de clusters é encontrado no ponto em que a queda na inércia começa a se \"nivelar\", formando um \"cotovelo\" no gráfico.\n",
        "* A inércia quantifica o quão dispersos estão os pontos dentro de cada cluster,  é calculada como a soma das distâncias ao quadrado entre cada ponto e o centróide do cluster mais próximo.\n",
        "\n"
      ],
      "metadata": {
        "id": "i9aL1tglBb2Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m940DNtxjO1i"
      },
      "source": [
        "# Dados\n",
        "X = dados\n",
        "\n",
        "inertia = []\n",
        "for n in range(1 , 11):\n",
        "    clf = KMeans(n_clusters = n , random_state= 1984)\n",
        "    clf.fit(X)\n",
        "    inertia.append(clf.inertia_)\n",
        "\n",
        "plt.figure(1 , figsize = (15 ,6))\n",
        "plt.plot(np.arange(1 , 11) , inertia , 'o')\n",
        "plt.plot(np.arange(1 , 11) , inertia , '-' , alpha = 0.5)\n",
        "plt.xlabel('Number of Clusters') , plt.ylabel('Inertia')\n",
        "\n",
        "# adicionado depois... ;-)\n",
        "plt.plot(3 , inertia[2] , 'P', alpha = 1, color = 'red')\n",
        "plt.text(3 + 0.2 , inertia[2] , '...Elbow point')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na dúvida, vamos usar 3 clusters!"
      ],
      "metadata": {
        "id": "PfWdv4lJJq5A"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaXGnVO4jPo7"
      },
      "source": [
        "X = dados # Dados\n",
        "seed = 1\n",
        "clf = KMeans(n_clusters = 3 , random_state = seed) # Declara o modelo\n",
        "clf.fit(X) # Calcula\n",
        "\n",
        "# Resultados\n",
        "labels = clf.labels_ # Indica os clusters para cada amostra (linha)\n",
        "centroids = clf.cluster_centers_ # Indica as coordenadas dos centróides - centróides nas linhas e coordenadas nas colunas\n",
        "\n",
        "print(labels)\n",
        "print(centroids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk85Vt9hkpFY"
      },
      "source": [
        "dados['cluster'] = labels\n",
        "print(dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exibindo os clusters\n",
        "Usando só duas variáveis: muder e urbanpop. Por que não podemos usar todas as variáveis?"
      ],
      "metadata": {
        "id": "zseMrvP9YZqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = plt.figure(figsize=(9,8))\n",
        "\n",
        "plt.scatter( x = 'Murder' ,y = 'UrbanPop' , data = dados , c =labels , s = 100)\n",
        "plt.scatter(x = centroids[ : ,0] , y =  centroids[ : ,2] , s = 100 , c = 'green' , alpha = 0.5, marker=\"*\")\n",
        "\n",
        "for line in range(0,dados.shape[0]):\n",
        "     plt.text(dados.Murder[line], dados.UrbanPop[line], dados.index[line],\n",
        "              horizontalalignment='center',\n",
        "              size='x-small',\n",
        "              color='black')\n",
        "\n",
        "plt.ylabel('UrbanPop') , plt.xlabel('Murder')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9VHTxxyFBNOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explorando os resultados"
      ],
      "metadata": {
        "id": "-0KZcdQ9LVme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tamanho dos Clusters"
      ],
      "metadata": {
        "id": "M05B9-beFefO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzm5KRyFmIsf"
      },
      "source": [
        "Verifique ainda se os grupos formados não levam a um grupo excessivamente grande (90% dos dados por exemplo) ou pequeno (1% dos dados por exemplos)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados.cluster.value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "C5klZjXcZxI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwYEsbzLmcg-"
      },
      "source": [
        "### Caracterizando os Grupos\n",
        "\n",
        "Vamos explorar esses grupos procurando características comuns. Vamos usar a base de dados original (sem transformações). Vamos importar novamente a base de dados."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USArrests.csv',index_col=0)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6e7Gg86Aafaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos adicionar a coluna \"cluster\" usando o modelo anterior"
      ],
      "metadata": {
        "id": "rXMNztuFaldy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['cluster'] = labels\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cqFY9l8Mak6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLnn99Z5mf7L"
      },
      "source": [
        "df.groupby('cluster').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analise os resultados!"
      ],
      "metadata": {
        "id": "1mjWPf9da9uG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8XsYm6HzPbM"
      },
      "source": [
        "## **Experimente você**\n",
        "\n",
        "Empregue o seguinte dataset `iris`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Carregar a base de dados Iris\n",
        "iris_data = load_iris()\n",
        "df_iris = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
        "df_iris\n"
      ],
      "metadata": {
        "id": "jlA7IiM2XOmT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}