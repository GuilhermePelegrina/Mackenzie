{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN59ZOoK/mhTQ5aUE4evd+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuilhermePelegrina/Mackenzie/blob/main/Aulas/TIC/Projeto_C1_avaliacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/logo_mackenzie.png'>"
      ],
      "metadata": {
        "id": "iz3c9tOgxfJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Avaliação Projeto C1**\n",
        "\n",
        "Relembrando, como descrito no plano da disciplina, o Projeto C1 consiste em uma atividade individual onde os alunos terão a opção de participar de uma competição com o intuito de resolver um problema de classificação. Os três alunos cujos modelos levarem aos maiores desempenhos do classificador, medido em termos da acurácia, terão a nota C1 igual a 1. Em caso de empate, será utilizada uma métrica de equidade apresentada no dia da avaliação do projeto. Os alunos vencedores também explicarão para o restante da turma as estratégias utilizadas para a construção da inteligência computacional.\n",
        "\n",
        "Para esta atividade, usamos a base de dados [COMPAS Recidivism Risk](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing), da ProPublica. Essa base de dados ficou conhecida por apresentar vieses raciais."
      ],
      "metadata": {
        "id": "ZQAF1zAtxgQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliando o modelo treinado\n",
        "\n",
        "Para avaliar o modelo, use o conjunto de dados disponível no link abaixo:\n",
        "\n",
        "https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/Datasets/data_compas_projC1_test.csv\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y3GpQPOpzaCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo os dados de teste\n",
        "\n",
        "dados_teste = pd.read_csv('https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/Datasets/data_compas_projC1_test.csv')\n",
        "dados_test.head()"
      ],
      "metadata": {
        "id": "xFBjafRr5Z9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro, separe os dados de entrada (`X_test`) e os dados de saída (`y_test`). Depois, ajuste os dados de teste para poder usá-lo no modelo treinado:\n",
        "\n",
        "- Caso tenha feito uma normalização dos dados de treinamento, normalize, também, os dados de teste\n",
        "\n",
        "- Caso tenha selecionado um subconjunto das colunas, selecione, também, esse subconjunto dos dados de teste.\n",
        "\n",
        "- Caso tenha feito alguma transformação de variáveis categóricas em dummies, faça, também, nos dados de teste.\n",
        "\n",
        "**Atenção:** Para os dados de teste, mantenha as mesmas colunas (e na mesma ordem) que foram usados no treinamento."
      ],
      "metadata": {
        "id": "vfKQLn-w5raM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base em seu modelo treinado (suponha que ele se chame `model`), verifique a acurácia obtida."
      ],
      "metadata": {
        "id": "oiGpQeiD5Zdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "mcLQiPNt5cbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Em caso de empate, avalie a equidade em relação ao componente racial!"
      ],
      "metadata": {
        "id": "2ECfFbwd7XDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Equidade em Aprendizado de Máquina**\n",
        "\n",
        "Além de procurar por melhores desempenhos em modelos de aprendizado de máquina, há também preocupações éticas de seu uso. São frequentes os casos nos quais há disparidades éticas associadas a aspectos sensíveis da população, como gênero, raça, faixa etária, etc.\n",
        "\n",
        "Com o intuito de eliminar tais disparidades, diversas regulações sobre o uso da Inteligência Artificial vem surgindo pelo mundo todo. Via de regra, a recomendação (ou, mais precisamente, a *obrigação*) é que os modelos de intelgência artificial / aprendizado de máquina sejam capazes de lidar com os problemas práticos mas que não gerem impactos negativos (dentre eles, os ligados às disparidades éticas) na população.\n",
        "\n",
        "Para ilustrar esses cenários \"injustos\", vamos avaliar e comparar os desempenhos do classificador, nos dados COMPAS, para brancos e negros.\n",
        "\n",
        "Nos comandos abaixo, há um exemplo com os dados de treinamento. No caso do modelo que foi desenvolvido para o projeto, avalie os desempenhos nos dados de teste."
      ],
      "metadata": {
        "id": "JE1g_p8g7yiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLCCtBlZxdW1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dados = pd.read_csv('https://raw.githubusercontent.com/guilhermepelegrina/Mackenzie/main/Datasets/data_compas_projC1_train.csv')\n",
        "dados = dados.dropna()\n",
        "dados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.get_dummies(dados, columns=['sex', 'age_cat', 'race', 'c_charge_degree'])\n",
        "dados"
      ],
      "metadata": {
        "id": "Dn-kHJxHBX4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dados.drop(columns=[\"score_risk\"])\n",
        "y = dados['score_risk']"
      ],
      "metadata": {
        "id": "wlcetIgEClPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "seed = 20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state=seed)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "seed = 20\n",
        "modelo = DecisionTreeClassifier(criterion='entropy',random_state=seed)\n",
        "modelo.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "bvw50LOhJnqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando o modelo - Emprega o conjunto de teste\n",
        "\n",
        "y_pred = modelo.predict(X_test)"
      ],
      "metadata": {
        "id": "ZQ0HeCqnLFpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Medidas de desempenho - Acurácia\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "8mCoug79L9T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "bSpii_9ErqrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparando a acurácia em relação aos brancos e negros\n",
        "\n",
        "accuracy_brancos = accuracy_score(y_test[X_test['race_Caucasian'] == 1], y_pred[X_test['race_Caucasian'] == 1])\n",
        "print(\"Acurácia para brancos:\", accuracy_brancos)\n",
        "\n",
        "accuracy_negros = accuracy_score(y_test[X_test['race_African-American'] == 1], y_pred[X_test['race_African-American'] == 1])\n",
        "print(\"Acurácia para negros:\", accuracy_negros)"
      ],
      "metadata": {
        "id": "IUiS0tZWrhNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparando o número de indivíduos erroneamente classificados como reincidentes, em relação aos brancos e negros\n",
        "\n",
        "erro_brancos = len(y_test[(X_test['race_Caucasian'] == 1) & (y_test[y_test == -1]) & (y_test[y_pred == 1])])/len(y_test[X_test['race_Caucasian'] == 1])\n",
        "print(\"Erro para brancos:\", erro_brancos)\n",
        "\n",
        "erro_negros = len(y_test[(X_test['race_African-American'] == 1) & (y_test[y_test == -1]) & (y_test[y_pred == 1])])/len(y_test[X_test['race_African-American'] == 1])\n",
        "print(\"Erro para negros:\", erro_negros)\n",
        "\n",
        "print('Diferença:', erro_negros - erro_brancos)"
      ],
      "metadata": {
        "id": "XSbQCgEXtCR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparando o número de indivíduos erroneamente classificados como não-reincidentes, em relação aos brancos e negros\n",
        "\n",
        "erro_brancos = len(y_test[(X_test['race_Caucasian'] == 1) & (y_test[y_test == 1]) & (y_test[y_pred == -1])])/len(y_test[X_test['race_Caucasian'] == 1])\n",
        "print(\"Erro para brancos:\", erro_brancos)\n",
        "\n",
        "erro_negros = len(y_test[(X_test['race_African-American'] == 1) & (y_test[y_test == 1]) & (y_test[y_pred == -1])])/len(y_test[X_test['race_African-American'] == 1])\n",
        "print(\"Erro para negros:\", erro_negros)\n",
        "\n",
        "print('Diferença:', erro_brancos - erro_negros)"
      ],
      "metadata": {
        "id": "8VG9RMiar_l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agora, testem no modelo de vocês o quanto ele está criando vieses raciais!"
      ],
      "metadata": {
        "id": "oiFn85Z0xuej"
      }
    }
  ]
}